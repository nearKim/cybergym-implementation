# Default configuration for CyberGym experiments

defaults:
  - _self_
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

# Environment settings
env:
  name: "CyberSecurityEnv"
  n_agents: 2
  observation_dim: 64
  action_dim: 10
  max_steps: 1000
  reward_scale: 1.0

# Agent settings
agent:
  type: "PPO"
  learning_rate: 3e-4
  hidden_dims: [256, 128]
  use_attention: true
  
  # PPO specific
  gamma: 0.99
  gae_lambda: 0.95
  clip_ratio: 0.2
  value_loss_coef: 0.5
  entropy_coef: 0.01
  max_grad_norm: 0.5

# Training settings
training:
  total_timesteps: 1000000
  n_envs: 8
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  eval_freq: 10000
  save_freq: 50000
  log_interval: 100

# Opponent synthesis settings  
opponent:
  use_adaptive: true
  population_size: 10
  selection_method: "tournament"
  mutation_rate: 0.1
  update_freq: 5000

# Experiment settings
experiment:
  seed: 42
  device: "cuda"
  wandb:
    project: "cybergym"
    entity: null
    tags: ["baseline"]
  checkpoint_dir: "checkpoints"
  log_dir: "logs"

# Hydra settings
hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}