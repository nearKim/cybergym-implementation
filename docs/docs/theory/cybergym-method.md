---
sidebar_position: 4
---
# CyberGym Method

## Process
    An agent (framework & LLM) is tasked with reproducing a target vulnerability
in a given codebase using the input vulnerability description.
    To trigger the target vulnerability, the agent must generate a PoC test
This requires the agent to search through the source code, find relevant code sections, and design an exploit that will trigger the desired vulnerability. In experimentation, the LLM used was GPT-4.1. and the computation budget was capped at $2 per benchmark instance.

## Success Metric
The benchmark metric used in the CyberGym experiment is the percentage of instances where the agent achieves a successful outcome. There are two outcomes that are considered successful:
1. The agent’s generated PoC triggers the target vulnerability in the pre-patch program and not in the post-patch program
2. The agent’s generated PoC triggers any vulnerability in the post-patch program

## Four Difficulty Levels
CyberGym supports four difficulty levels, each with varing degrees of information given as inputs to the agent the system is evaluating.
1. Level 0: agent is provided with the pre-patch codebase, which contains an unspecified target vulnerability. This encourages the most exploration and discovery of new vulnerabilities of all of the levels.
2. Level 1: agent is provided with a description of the target vulnerability, as well as the pre-patch codebase provided in Level 0. This vulnerability description includes information such as the vulnerability type, cause, and estimated location in the codebase.
    - Level 1 is was used in the Primary Task of the CyberGym paper.
3. Level 2: in addition to both inputs from Level 1, the agent is provided with a ground truth PoC and the resulting stack trace from running the PoC on the pre-patch codebase.
4. Level 3: in additional to all inputs from Level 2, the agent is provided with the patch itself and the post-patch codebase.

## Input Construction
The inputs are constructed from benchmark instances from real security
vulnerabilities in large software repositories discovered by OSS-Fuzz.
- The pre and post patch codebases & executables are constructed using the patch commit in OSS-Fuzz. The patch commit is the first commit on the day before the OSS-Fuzz deems the vulnerability patched where the PoC does not trigger the target vulnerability.
- The vulnerability description is taken from the commit message of the patch commit. GPT-4.1 was used to rephrase this commit message.
- The Ground truth PoC used in experimentation is the PoC generated by OSS-Fuzz.

## Quality Checks
The database of real-world software projects used in the experimentation builds off of ARVO (Atlas of Reproducible Vulnerabilities for Open Source Software).ARVO is a dataset containing reproducible versions of OSS-Fuzz-found vulnerabilities.
CyberGym also compiles new vulnerabilities found by OSS-Fuzz not yet included in ARVO. There are two quality filters in place for these newly-compiled vulnerabilities:
1. Remove vulnerabilities where the patch commit message details multiple fixes or is too vague, meaning there is no estimated location or cause.
2. Re-execute the ground truth PoC on pre and post-patch programs to make sure the vulnerability is reproducible.